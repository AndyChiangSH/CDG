{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NSu6sKJHco7j",
        "dFZWoZffcx_w",
        "-UiJnYVLcs5K",
        "RqDYqVo4c14s",
        "5OsDkNIGd8qR",
        "6LFphmr0iQIw",
        "u6e34C_1X0Io",
        "PxHW8Dr-qdAf",
        "FnlXdfcfm87V"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT_fine-tune\n",
        "\n",
        "This is the code to fine-tune the [**bert-base-uncased**](https://huggingface.co/bert-base-uncased) pre-train language model by [**CLOTH**](https://www.cs.cmu.edu/~glai1/data/cloth/) or [**DGen**](https://github.com/DRSY/DGen) datasets.\n",
        "\n",
        "* Paper: \"CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model\"\n",
        "* Author: AndyChiangSH\n",
        "* Time: 2022/10/15\n",
        "* GitHub: https://github.com/AndyChiangSH/CDGP"
      ],
      "metadata": {
        "id": "tDxJQr-dxZAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download datasets"
      ],
      "metadata": {
        "id": "NSu6sKJHco7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLOTH"
      ],
      "metadata": {
        "id": "dFZWoZffcx_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AndyChiangSH/CDGP/raw/main/datasets/CLOTH.zip"
      ],
      "metadata": {
        "id": "M_g5JJsecLet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./CLOTH.zip -d ./CLOTH"
      ],
      "metadata": {
        "id": "rFbRT-jzcSHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGen"
      ],
      "metadata": {
        "id": "-UiJnYVLcs5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AndyChiangSH/CDGP/raw/main/datasets/DGen.zip"
      ],
      "metadata": {
        "id": "KEBQ7Ns8aLMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./DGen.zip -d ./DGen"
      ],
      "metadata": {
        "id": "78eFmRnwa0Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "RqDYqVo4c14s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLOTH"
      ],
      "metadata": {
        "id": "5OsDkNIGd8qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"./CLOTH/CLOTH_train_cleaned.json\", \"r\") as file:\n",
        "    dataset = json.load(file)\n",
        "\n",
        "print(len(dataset))\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "NnZyAgWweNQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGen"
      ],
      "metadata": {
        "id": "XPQhwZOjd-Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"./DGen/DGen_train_cleaned.json\", \"r\") as file:\n",
        "    dataset = json.load(file)\n",
        "\n",
        "print(len(dataset))\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "dftoLEE0gSmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data masking"
      ],
      "metadata": {
        "id": "H-5-hMEBlGmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "\n",
        "input_list = list()\n",
        "label_list = list()\n",
        "\n",
        "for data in tqdm(dataset):\n",
        "  answer = data[\"answer\"]\n",
        "  distractors = data[\"distractors\"]\n",
        "  sentence = data[\"sentence\"]\n",
        "  mask_sentence = sentence.replace(\"**blank**\", \"[MASK]\")\n",
        "  mask_sentence += \" [SEP] \" + answer\n",
        "  for distractor in distractors:\n",
        "    dis_sentence = mask_sentence.replace(\"[MASK]\", distractor)\n",
        "    input_list.append(mask_sentence)\n",
        "    label_list.append(dis_sentence)"
      ],
      "metadata": {
        "id": "qrUA00jmeAb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input_list:\", len(input_list))\n",
        "print(input_list[:10])"
      ],
      "metadata": {
        "id": "DMAVtU6Bf8Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"label_list:\", len(label_list))\n",
        "print(label_list[:10])"
      ],
      "metadata": {
        "id": "Ukfi4hjof9_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune BERT"
      ],
      "metadata": {
        "id": "j9u34640hYog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "BiBflb2Phdo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PLM = \"bert-base-uncased\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCH = 1\n",
        "LR = 0.0001\n",
        "MAX_LENGTH = 64"
      ],
      "metadata": {
        "id": "Ix9FuxV7huFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup the Dataset"
      ],
      "metadata": {
        "id": "6LFphmr0iQIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dic = {\"input\": input_list, \"label\": label_list}"
      ],
      "metadata": {
        "id": "bzgax-4LXVoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_dict(data_dic)"
      ],
      "metadata": {
        "id": "WN91FANHXe_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))"
      ],
      "metadata": {
        "id": "f9fT6hmCXfZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup the DataLoader"
      ],
      "metadata": {
        "id": "u6e34C_1X0Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "bnVTU4hfYB9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataloader))"
      ],
      "metadata": {
        "id": "9M3rVHqSkSSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tune the model"
      ],
      "metadata": {
        "id": "GHyV_pt8bOEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PLM)\n",
        "model = BertForMaskedLM.from_pretrained(PLM, return_dict=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "lXQX6Cv3i_df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process bar\n",
        "num_training_steps = EPOCH * len(dataloader)\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "# start fine-tune\n",
        "loss_history = []\n",
        "for epoch in range(EPOCH):\n",
        "  for batch in dataloader:\n",
        "    inputs = tokenizer(batch[\"input\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "    labels = tokenizer(batch[\"label\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    output = model(**inputs.to(device), labels=labels.to(device))\n",
        "    optimizer.zero_grad()\n",
        "    loss = output.loss\n",
        "    logits = output.logits\n",
        "    loss_history.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    progress_bar.update(1)\n",
        "  \n",
        "  print(f\"[epoch {epoch+1}] loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "7xYOFPYXjDz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show the loss line chart"
      ],
      "metadata": {
        "id": "S9WLA_XcppFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_history)\n",
        "print(len(loss_history))"
      ],
      "metadata": {
        "id": "EUbkbNQCby7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paint training loss graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.title('Training loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('batch')\n",
        "plt.legend(['loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MzKUPFUUb4Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ],
      "metadata": {
        "id": "9WH-fVMshZvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(\"./cdgp-csg-bert-dgen\")"
      ],
      "metadata": {
        "id": "Seo9U4XLjx80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete the model"
      ],
      "metadata": {
        "id": "7jMzCsZImcIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "del model_to_save\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mVK_aPCsmZIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "PxHW8Dr-qdAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing data"
      ],
      "metadata": {
        "id": "FnlXdfcfm87V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = {\n",
        "    \"q1\": {\n",
        "        \"sentence\": \"To make Jane live a [MASK] life, Mother was very careful about spending money. [SEP] happy\",\n",
        "        \"answer\": \"happy\",\n",
        "        \"distractors\": [\"poor\", \"busy\", \"sad\"]\n",
        "    },\n",
        "    \"q2\": {\n",
        "        \"sentence\": \"[MASK] , Jane didn't understand her. [SEP] However\",\n",
        "        \"answer\": \"However\",\n",
        "        \"distractors\": [\"Though\", \"Although\", \"Or\"]\n",
        "    },\n",
        "    \"q3\": {\n",
        "        \"sentence\": \"Every day Mother was busy with her [MASK] while Jane was studying at school, so they had little time to enjoy themselves. [SEP] work\",\n",
        "        \"answer\": \"work\",\n",
        "        \"distractors\": [\"writing\", \"housework\", \"research\"]\n",
        "    },\n",
        "    \"q4\": {\n",
        "        \"sentence\": \"One day, Mother realized Jane was unhappy and even [MASK] to her. [SEP] unfriendly\",\n",
        "        \"answer\": \"unfriendly\",\n",
        "        \"distractors\": [\"loyal\", \"kind\", \"cruel\"]\n",
        "    },\n",
        "    \"q5\": {\n",
        "        \"sentence\": \"The old man was waiting for a ride across the [MASK] . [SEP] river\",\n",
        "        \"answer\": \"river\",\n",
        "        \"distractors\": [\"town\", \"country\", \"island\"]\n",
        "    },\n",
        "    \"q6\": {\n",
        "        \"sentence\": \"I felt uncomfortable and out of place as the professor carefully [MASK] what she expected us to learn. [SEP] explained\",\n",
        "        \"answer\": \"explained\",\n",
        "        \"distractors\": [\"showed\", \"designed\", \"offered\"]\n",
        "    },\n",
        "    \"q7\": {\n",
        "        \"sentence\": \"As I listened, I couldn't help but [MASK] of my own oldest daughter. [SEP] think\",\n",
        "        \"answer\": \"think\",\n",
        "        \"distractors\": [\"speak\", \"talk\", \"hear\"]\n",
        "    },\n",
        "    \"q8\": {\n",
        "        \"sentence\": \"As we were [MASK] on the third floor for old people with Alzheimer, most of them stared off at the walls or floor. [SEP] singing\",\n",
        "        \"answer\": \"singing\",\n",
        "        \"distractors\": [\"meeting\", \"gathering\", \"dancing\"]\n",
        "    },\n",
        "    \"q9\": {\n",
        "        \"sentence\": \"As we got [MASK] with each song, she did as well. [SEP] louder\",\n",
        "        \"answer\": \"louder\",\n",
        "        \"distractors\": [\"higher\", \"nearer\", \"faster\"]\n",
        "    },\n",
        "    \"q10\": {\n",
        "        \"sentence\": \"Mr. Petri, [MASK] injured in the fire, was rushed to hospital. [SEP] seriously\",\n",
        "        \"answer\": \"seriously\",\n",
        "        \"distractors\": [\"blindly\", \"hardly\", \"slightly\"]\n",
        "    },\n",
        "    \"q11\": {\n",
        "        \"sentence\": \"If an object is attracted to a magnet, the object is most likely made of [MASK]. [SEP] metal\",\n",
        "        \"answer\": \"metal\",\n",
        "        \"distractors\": [\"wood\", \"plastic\", \"cardboard\"]\n",
        "    },\n",
        "    \"q12\": {\n",
        "        \"sentence\": \"the main organs of the respiratory system are [MASK]. [SEP] lungs\",\n",
        "        \"answer\": \"lungs\",\n",
        "        \"distractors\": [\"ovaries\", \"intestines\", \"kidneys\"]\n",
        "    },\n",
        "    \"q13\": {\n",
        "        \"sentence\": \"The products of photosynthesis are glucose and [MASK] else. [SEP] oxygen\",\n",
        "        \"answer\": \"oxygen\",\n",
        "        \"distractors\": [\"carbon\", \"hydrogen\", \"nitrogen\"]\n",
        "    },\n",
        "    \"q14\": {\n",
        "        \"sentence\": \"frogs have [MASK] eyelid membranes. [SEP] three\",\n",
        "        \"answer\": \"three\",\n",
        "        \"distractors\": [\"two\", \"four\", \"one\"]\n",
        "    },\n",
        "    \"q15\": {\n",
        "        \"sentence\": \"the only known planet with large amounts of water is [MASK]. [SEP] earth\",\n",
        "        \"answer\": \"earth\",\n",
        "        \"distractors\": [\"saturn\", \"jupiter\", \"mars\"]\n",
        "    },\n",
        "    \"q16\": {\n",
        "        \"sentence\": \"[MASK] is responsible for erosion by flowing water and glaciers. [SEP] gravity\",\n",
        "        \"answer\": \"gravity\",\n",
        "        \"distractors\": [\"kinetic\", \"electromagnetic\", \"weight\"],\n",
        "    },\n",
        "    \"q17\": {\n",
        "        \"sentence\": \"Common among mammals and insects , pheromones are often related to [MASK] type of behavior. [SEP] reproductive\",\n",
        "        \"answer\": \"reproductive\",\n",
        "        \"distractors\": [\"aggressive\", \"immune\", \"cardiac\"]\n",
        "    },\n",
        "    \"q18\": {\n",
        "        \"sentence\": \"[MASK] can reproduce by infecting the cell of a living host. [SEP] virus\",\n",
        "        \"answer\": \"virus\",\n",
        "        \"distractors\": [\"bacteria\", \"mucus\", \"carcinogens\"]\n",
        "    },\n",
        "    \"q19\": {\n",
        "        \"sentence\": \"proteins are encoded by [MASK]. [SEP] genes\",\n",
        "        \"answer\": \"genes\",\n",
        "        \"distractors\": [\"DNA\", \"RNA\", \"codons\"]\n",
        "    },\n",
        "    \"q20\": {\n",
        "        \"sentence\": \"Producers at the base of ecological food webs are also known as [MASK]. [SEP] autotrophic\",\n",
        "        \"answer\": \"autotrophic\",\n",
        "        \"distractors\": [\"endoscopic\", \"symbiotic\", \"mutualistic\"],\n",
        "    },\n",
        "    \"q21\": {\n",
        "        \"sentence\": \"Today morning, I saw a [MASK] sitting on the wall. [SEP] cat\",\n",
        "        \"answer\": \"cat\",\n",
        "        \"distractors\": [],\n",
        "    },\n",
        "    \"q22\": {\n",
        "        \"sentence\": \"Ukrainian presidential adviser says situation is ' [MASK] control' in suburbs and outskirts of Kyiv. [SEP] under\",\n",
        "        \"answer\": \"under\",\n",
        "        \"distractors\": [],\n",
        "    },\n",
        "    \"q23\": {\n",
        "        \"sentence\": \"I don't think that after what is [MASK] now, Ukraine has weak positions. [SEP] happening\",\n",
        "        \"answer\": \"happening\",\n",
        "        \"distractors\": [],\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "8-HlXvwSm_ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "9z_ovOkEm64A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PLM)\n",
        "model = BertForMaskedLM.from_pretrained(\"./cdgp-csg-bert-dgen\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "KCbn5CYXm64A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate distractors"
      ],
      "metadata": {
        "id": "E1Ju8CnBplJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", tokenizer=tokenizer, model=model, top_k=10)"
      ],
      "metadata": {
        "id": "_pX61ghWoXvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(questions[\"q1\"][\"sentence\"])"
      ],
      "metadata": {
        "id": "uJ6nTUDcohsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
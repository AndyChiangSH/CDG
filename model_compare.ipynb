{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKtTacFszaFj"
   },
   "source": [
    "## 引用相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ry86IFrPzbn4"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GolSA9-MVXox"
   },
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT_CLOTH_model: BERT + CLOTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertForMaskedLM, pipeline\n",
    "\n",
    "dir_path = r\"./models/CSG/BERT_CLOTH_model\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(os.path.join(dir_path, \"config.json\"))\n",
    "csg_model1 = BertForMaskedLM.from_pretrained(os.path.join(dir_path, \"pytorch_model.bin\"), from_tf=bool('.ckpt' in 'bert-base-uncased'), config=config)\n",
    "csg_model1.eval()\n",
    "\n",
    "unmasker1 = pipeline('fill-mask', tokenizer=tokenizer, config=config, model=csg_model1, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT_CLOTH_model: BERT + DGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertForMaskedLM, pipeline\n",
    "\n",
    "dir_path = r\"./models/CSG/BERT_DGen_model1\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(os.path.join(dir_path, \"config.json\"))\n",
    "csg_model2 = BertForMaskedLM.from_pretrained(os.path.join(dir_path, \"pytorch_model.bin\"), from_tf=bool('.ckpt' in 'bert-base-uncased'), config=config)\n",
    "csg_model2.eval()\n",
    "\n",
    "unmasker2 = pipeline('fill-mask', tokenizer=tokenizer, config=config, model=csg_model2, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT_CLOTH_DGen_model: BERT + CLOTH + DGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertForMaskedLM, pipeline\n",
    "\n",
    "dir_path = r\"./models/CSG/BERT_CLOTH_DGen_model1\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(os.path.join(dir_path, \"config.json\"))\n",
    "csg_model3 = BertForMaskedLM.from_pretrained(os.path.join(dir_path, \"pytorch_model.bin\"), config=config, from_tf=bool('.ckpt' in 'bert-base-uncased'))\n",
    "csg_model3.eval()\n",
    "\n",
    "unmasker3 = pipeline('fill-mask', tokenizer=tokenizer, config=config, model=csg_model3, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo questions\n",
    "\n",
    "* q1 ~ q10 取自CLOTH資料集，名詞2個，動詞3個，形容詞3個，副詞2個\n",
    "* q11 ~ q20 取自DGen資料集，名詞8個，形容詞1個，數量詞1個\n",
    "* q21 ~ q23 取自網路文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {\n",
    "    \"q1\": {\n",
    "        \"sentence\": \"To make Jane live a [MASK] life, Mother was very careful about spending money. [SEP] happy\",\n",
    "        \"answer\": \"happy\",\n",
    "        \"distractors\": [\"poor\", \"busy\", \"sad\"]\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"sentence\": \"[MASK] , Jane didn't understand her. [SEP] However\",\n",
    "        \"answer\": \"However\",\n",
    "        \"distractors\": [\"Though\", \"Although\", \"Or\"]\n",
    "    },\n",
    "    \"q3\": {\n",
    "        \"sentence\": \"Every day Mother was busy with her [MASK] while Jane was studying at school, so they had little time to enjoy themselves. [SEP] work\",\n",
    "        \"answer\": \"work\",\n",
    "        \"distractors\": [\"writing\", \"housework\", \"research\"]\n",
    "    },\n",
    "    \"q4\": {\n",
    "        \"sentence\": \"One day, Mother realized Jane was unhappy and even [MASK] to her. [SEP] unfriendly\",\n",
    "        \"answer\": \"unfriendly\",\n",
    "        \"distractors\": [\"loyal\", \"kind\", \"cruel\"]\n",
    "    },\n",
    "    \"q5\": {\n",
    "        \"sentence\": \"The old man was waiting for a ride across the [MASK] . [SEP] river\",\n",
    "        \"answer\": \"river\",\n",
    "        \"distractors\": [\"town\", \"country\", \"island\"]\n",
    "    },\n",
    "    \"q6\": {\n",
    "        \"sentence\": \"I felt uncomfortable and out of place as the professor carefully [MASK] what she expected us to learn. [SEP] explained\",\n",
    "        \"answer\": \"explained\",\n",
    "        \"distractors\": [\"showed\", \"designed\", \"offered\"]\n",
    "    },\n",
    "    \"q7\": {\n",
    "        \"sentence\": \"As I listened, I couldn't help but [MASK] of my own oldest daughter. [SEP] think\",\n",
    "        \"answer\": \"think\",\n",
    "        \"distractors\": [\"speak\", \"talk\", \"hear\"]\n",
    "    },\n",
    "    \"q8\": {\n",
    "        \"sentence\": \"As we were [MASK] on the third floor for old people with Alzheimer, most of them stared off at the walls or floor. [SEP] singing\",\n",
    "        \"answer\": \"singing\",\n",
    "        \"distractors\": [\"meeting\", \"gathering\", \"dancing\"]\n",
    "    },\n",
    "    \"q9\": {\n",
    "        \"sentence\": \"As we got [MASK] with each song, she did as well. [SEP] louder\",\n",
    "        \"answer\": \"louder\",\n",
    "        \"distractors\": [\"higher\", \"nearer\", \"faster\"]\n",
    "    },\n",
    "    \"q10\": {\n",
    "        \"sentence\": \"Mr. Petri, [MASK] injured in the fire, was rushed to hospital. [SEP] seriously\",\n",
    "        \"answer\": \"seriously\",\n",
    "        \"distractors\": [\"blindly\", \"hardly\", \"slightly\"]\n",
    "    },\n",
    "    \"q11\": {\n",
    "        \"sentence\": \"If an object is attracted to a magnet, the object is most likely made of [MASK]. [SEP] metal\",\n",
    "        \"answer\": \"metal\",\n",
    "        \"distractors\": [\"wood\", \"plastic\", \"cardboard\"]\n",
    "    },\n",
    "    \"q12\": {\n",
    "        \"sentence\": \"the main organs of the respiratory system are [MASK]. [SEP] lungs\",\n",
    "        \"answer\": \"lungs\",\n",
    "        \"distractors\": [\"ovaries\", \"intestines\", \"kidneys\"]\n",
    "    },\n",
    "    \"q13\": {\n",
    "        \"sentence\": \"The products of photosynthesis are glucose and [MASK] else. [SEP] oxygen\",\n",
    "        \"answer\": \"oxygen\",\n",
    "        \"distractors\": [\"carbon\", \"hydrogen\", \"nitrogen\"]\n",
    "    },\n",
    "    \"q14\": {\n",
    "        \"sentence\": \"frogs have [MASK] eyelid membranes. [SEP] three\",\n",
    "        \"answer\": \"three\",\n",
    "        \"distractors\": [\"two\", \"four\", \"one\"]\n",
    "    },\n",
    "    \"q15\": {\n",
    "        \"sentence\": \"the only known planet with large amounts of water is [MASK]. [SEP] earth\",\n",
    "        \"answer\": \"earth\",\n",
    "        \"distractors\": [\"saturn\", \"jupiter\", \"mars\"]\n",
    "    },\n",
    "    \"q16\": {\n",
    "        \"sentence\": \"[MASK] is responsible for erosion by flowing water and glaciers. [SEP] gravity\",\n",
    "        \"answer\": \"gravity\",\n",
    "        \"distractors\": [\"kinetic\", \"electromagnetic\", \"weight\"],\n",
    "    },\n",
    "    \"q17\": {\n",
    "        \"sentence\": \"Common among mammals and insects , pheromones are often related to [MASK] type of behavior. [SEP] reproductive\",\n",
    "        \"answer\": \"reproductive\",\n",
    "        \"distractors\": [\"aggressive\", \"immune\", \"cardiac\"]\n",
    "    },\n",
    "    \"q18\": {\n",
    "        \"sentence\": \"[MASK] can reproduce by infecting the cell of a living host. [SEP] virus\",\n",
    "        \"answer\": \"virus\",\n",
    "        \"distractors\": [\"bacteria\", \"mucus\", \"carcinogens\"]\n",
    "    },\n",
    "    \"q19\": {\n",
    "        \"sentence\": \"proteins are encoded by [MASK]. [SEP] genes\",\n",
    "        \"answer\": \"genes\",\n",
    "        \"distractors\": [\"DNA\", \"RNA\", \"codons\"]\n",
    "    },\n",
    "    \"q20\": {\n",
    "        \"sentence\": \"Producers at the base of ecological food webs are also known as [MASK]. [SEP] autotrophic\",\n",
    "        \"answer\": \"autotrophic\",\n",
    "        \"distractors\": [\"endoscopic\", \"symbiotic\", \"mutualistic\"],\n",
    "    },\n",
    "    \"q21\": {\n",
    "        \"sentence\": \"Today morning, I saw a [MASK] sitting on the wall. [SEP] cat\",\n",
    "        \"answer\": \"cat\",\n",
    "        \"distractors\": [],\n",
    "    },\n",
    "    \"q22\": {\n",
    "        \"sentence\": \"Ukrainian presidential adviser says situation is ' [MASK] control' in suburbs and outskirts of Kyiv. [SEP] under\",\n",
    "        \"answer\": \"under\",\n",
    "        \"distractors\": [],\n",
    "    },\n",
    "    \"q23\": {\n",
    "        \"sentence\": \"I don't think that after what is [MASK] now, Ukraine has weak positions. [SEP] happening\",\n",
    "        \"answer\": \"happening\",\n",
    "        \"distractors\": [],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare\n",
    "\n",
    "* CLOTH_model 在CLOTH上表現很好，但在DGen表現就不好了，太過General\n",
    "* DGen_model 比較specific在DGen的資料集上，在CLOTH上表現就不好\n",
    "* CLOTH&DGen_model 在兩個資料集表現都不錯，但在DGen上仍然不及DGen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_num = \"q10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: seriously\n",
      "dis: ['blindly', 'hardly', 'slightly']\n",
      "cs1: ['hardly', 'frequently', 'happily', 'strangely', 'quietly', 'slightly', 'regularly', 'finally', 'rarely', 'seriously']\n",
      "cs2: ['seriously', 'severely', 'critically', 'badly', 'injured', 'serious', 'slightly', 'injuries', 'fatally', 'mortally']\n",
      "cs3: ['hardly', 'suddenly', 'happily', 'gradually', 'luckily', 'usually', 'strangely', 'specially', 'finally', 'secretly']\n"
     ]
    }
   ],
   "source": [
    "answer = questions[question_num][\"answer\"].lower()\n",
    "dis = [d.lower() for d in questions[question_num][\"distractors\"]]\n",
    "\n",
    "cs1 = list()\n",
    "for cand in unmasker1(questions[question_num][\"sentence\"]):\n",
    "    cs1.append(cand[\"token_str\"].replace(\" \", \"\"))\n",
    "\n",
    "cs2 = list()\n",
    "for cand in unmasker2(questions[question_num][\"sentence\"]):\n",
    "    cs2.append(cand[\"token_str\"].replace(\" \", \"\"))\n",
    "\n",
    "cs3 = list()\n",
    "for cand in unmasker3(questions[question_num][\"sentence\"]):\n",
    "    cs3.append(cand[\"token_str\"].replace(\" \", \"\"))\n",
    "\n",
    "print(\"answer:\", answer)\n",
    "print(\"dis:\", dis)\n",
    "print(\"cs1:\", cs1)\n",
    "print(\"cs2:\", cs2)\n",
    "print(\"cs3:\", cs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較生成的和已知的中了幾個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs1_dis: 2, ['hardly', 'slightly']\n",
      "cs2_dis: 1, ['slightly']\n",
      "cs3_dis: 1, ['hardly']\n"
     ]
    }
   ],
   "source": [
    "cs1_dis = list()\n",
    "for c1 in cs1:\n",
    "    if c1 in dis:\n",
    "        cs1_dis.append(c1)\n",
    "\n",
    "cs2_dis = list()\n",
    "for c2 in cs2:\n",
    "    if c2 in dis:\n",
    "        cs2_dis.append(c2)\n",
    "\n",
    "cs3_dis = list()\n",
    "for c3 in cs3:\n",
    "    if c3 in dis:\n",
    "        cs3_dis.append(c3)\n",
    "\n",
    "print(f\"cs1_dis: {len(cs1_dis)}, {cs1_dis}\")\n",
    "print(f\"cs2_dis: {len(cs2_dis)}, {cs2_dis}\")\n",
    "print(f\"cs3_dis: {len(cs3_dis)}, {cs3_dis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 是否包含答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs1_ans = 1, index = 9\n",
      "cs2_ans = 1, index = 0\n",
      "cs3_ans = 0, index = -1\n"
     ]
    }
   ],
   "source": [
    "cs1_ans = 0\n",
    "cs1_ans_index = -1\n",
    "if answer in cs1:\n",
    "    cs1_ans = 1\n",
    "    cs1_ans_index = cs1.index(answer)\n",
    "\n",
    "cs2_ans = 0\n",
    "cs2_ans_index = -1\n",
    "if answer in cs2:\n",
    "    cs2_ans = 1\n",
    "    cs2_ans_index = cs2.index(answer)\n",
    "\n",
    "cs3_ans = 0\n",
    "cs3_ans_index = -1\n",
    "if answer in cs3:\n",
    "    cs3_ans = 1\n",
    "    cs3_ans_index = cs3.index(answer)\n",
    "\n",
    "print(f\"cs1_ans = {cs1_ans}, index = {cs1_ans_index}\")\n",
    "print(f\"cs2_ans = {cs2_ans}, index = {cs2_ans_index}\")\n",
    "print(f\"cs3_ans = {cs3_ans}, index = {cs3_ans_index}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3922e3c97c651be36ae2a74450309ec6ba42b89c1b16d216f29ae45749fd04d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('CDG-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
